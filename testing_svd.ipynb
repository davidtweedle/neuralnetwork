{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8fa3d91-bbcd-4231-8293-b118f3238f8a",
   "metadata": {},
   "source": [
    "Imports\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7656a8c-5b79-4472-9b75-4df85a6e8245",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from genericdlmodel import Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6275edf5-b017-4887-80d1-c7ae94bfbe6c",
   "metadata": {},
   "source": [
    "Download data\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b005bae4-8121-4132-8d5c-fe47f818ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_set = datasets.MNIST('data/', train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST('data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c5f18-d480-4570-812e-88330b1fceb1",
   "metadata": {},
   "source": [
    "Initializing hyperparameters\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47d884f4-0928-4d46-a89b-8e3a8c715c70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.5\n",
    "epochs = 14\n",
    "pixels_per_image = 28 * 28\n",
    "num_labels = 10\n",
    "batch_size = 64\n",
    "test_batch_size=1000\n",
    "dropout = 0\n",
    "hidden_layer_sizes = [512, 512]\n",
    "seed=101\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "update_rule = \"svd_lowrank\"\n",
    "update_args = {\"method\": \"randomized_svd\",\n",
    "               \"n_eigenvecs\": 3,\n",
    "               \"n_oversamples\": 2,\n",
    "               \"n_iter\": 2,\n",
    "               \"random_state\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0546cf5a-3b51-420c-b805-999baf7b27c3",
   "metadata": {},
   "source": [
    "Running the models\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e341785-189c-4551-852d-9d0aadcd3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ba1a7f-4225-420e-ae91-39dc5853a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct Neural Network in torch\n",
    "tl.set_backend(\"pytorch\")\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2bc1531-e2d7-46e2-b5f2-8f6ca446a2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12eb3048-4e39-477c-a368-3a8943b00da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36a5372f-7b4a-424a-9d46-3d0a71668558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_tensor_hook(grad):\n",
    "    if len(grad.size()) == 2:\n",
    "        U, S, Vh = tl.tenalg.svd_interface(grad, **update_args)\n",
    "        return (U * S) @ Vh\n",
    "    else:\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7202cec-0308-4304-b7b1-29047a412c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.262102 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.151608 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.121510 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.118345 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.097781 \n",
      "\n",
      "Epoch 6\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.092176 \n",
      "\n",
      "Epoch 7\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.083732 \n",
      "\n",
      "Epoch 8\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.082453 \n",
      "\n",
      "Epoch 9\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.085489 \n",
      "\n",
      "Epoch 10\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.091537 \n",
      "\n",
      "Epoch 11\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.095237 \n",
      "\n",
      "Epoch 12\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.096864 \n",
      "\n",
      "Epoch 13\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.085732 \n",
      "\n",
      "Epoch 14\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.086747 \n",
      "\n",
      "Done!\n",
      "CPU times: user 2h 15min 35s, sys: 22.1 s, total: 2h 15min 57s\n",
      "Wall time: 49min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for p in model.parameters():\n",
    "    p.register_hook(svd_tensor_hook)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "961c4ee3-1b42-44d0-8365-b2592f9eba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend(\"numpy\")\n",
    "train_set = datasets.MNIST('data/', train=True, download=True)\n",
    "test_set = datasets.MNIST('data/', train=False, download=True)\n",
    "def one_hot_encoding(labels, dim=10):\n",
    "    one_hot_labels = labels[..., None] == np.arange(dim)[None]\n",
    "    return one_hot_labels.astype(np.float64)\n",
    "    \n",
    "def to_numpy(dataset):\n",
    "    x, y = zip(*dataset)\n",
    "    x = np.array(x, dtype='float64')\n",
    "    x = x.reshape(x.shape[0], x.shape[1] * x.shape[2])\n",
    "    x /= 255.\n",
    "    y = one_hot_encoding(np.array(y, dtype='float64'), dim=10)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = to_numpy(train_set)\n",
    "x_test, y_test = to_numpy(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66fadb8c-7d00-4ed2-8125-e168a9535d4f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    rng=rng,\n",
    "    training_data_X=x_train,\n",
    "    training_data_y=y_train,\n",
    "    val_data_X=x_test,\n",
    "    val_data_y=y_test,\n",
    "    objective_function=\"categoricalcrossentropy\",\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    eps=1e-7\n",
    ")\n",
    "for output_size in hidden_layer_sizes:\n",
    "    model.add_layer(\n",
    "        output_size=output_size,\n",
    "        func_name=\"relu\",\n",
    "        dropout=dropout,\n",
    "        update_rule=update_rule,\n",
    "        update_args=update_args,\n",
    "    )\n",
    "model.add_final_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "101ce2e3-4933-4721-88e6-3c55f56e1b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "  Training loss:          0.361\n",
      "  Training accuracy:      0.888\n",
      "  Validation loss:        0.295\n",
      "  Validation accuracy:    0.904\n",
      "\n",
      "Epoch: 1\n",
      "  Training loss:          0.141\n",
      "  Training accuracy:      0.956\n",
      "  Validation loss:        0.476\n",
      "  Validation accuracy:    0.843\n",
      "\n",
      "Epoch: 2\n",
      "  Training loss:          0.094\n",
      "  Training accuracy:      0.969\n",
      "  Validation loss:        0.083\n",
      "  Validation accuracy:    0.974\n",
      "\n",
      "Epoch: 3\n",
      "  Training loss:          0.067\n",
      "  Training accuracy:      0.978\n",
      "  Validation loss:        0.085\n",
      "  Validation accuracy:    0.972\n",
      "\n",
      "Epoch: 4\n",
      "  Training loss:          0.047\n",
      "  Training accuracy:      0.984\n",
      "  Validation loss:        0.075\n",
      "  Validation accuracy:    0.977\n",
      "\n",
      "Epoch: 5\n",
      "  Training loss:          0.035\n",
      "  Training accuracy:      0.988\n",
      "  Validation loss:        0.108\n",
      "  Validation accuracy:    0.966\n",
      "\n",
      "Epoch: 6\n",
      "  Training loss:          0.024\n",
      "  Training accuracy:      0.992\n",
      "  Validation loss:        0.135\n",
      "  Validation accuracy:    0.964\n",
      "\n",
      "Epoch: 7\n",
      "  Training loss:          0.017\n",
      "  Training accuracy:      0.994\n",
      "  Validation loss:        0.079\n",
      "  Validation accuracy:    0.979\n",
      "\n",
      "Epoch: 8\n",
      "  Training loss:          0.017\n",
      "  Training accuracy:      0.995\n",
      "  Validation loss:        0.126\n",
      "  Validation accuracy:    0.973\n",
      "\n",
      "Epoch: 9\n",
      "  Training loss:          0.014\n",
      "  Training accuracy:      0.995\n",
      "  Validation loss:        0.081\n",
      "  Validation accuracy:    0.978\n",
      "\n",
      "Epoch: 10\n",
      "  Training loss:          0.007\n",
      "  Training accuracy:      0.998\n",
      "  Validation loss:        0.078\n",
      "  Validation accuracy:    0.981\n",
      "\n",
      "Epoch: 11\n",
      "  Training loss:          0.003\n",
      "  Training accuracy:      0.999\n",
      "  Validation loss:        0.068\n",
      "  Validation accuracy:    0.983\n",
      "\n",
      "Epoch: 12\n",
      "  Training loss:          0.002\n",
      "  Training accuracy:      1.000\n",
      "  Validation loss:        0.066\n",
      "  Validation accuracy:    0.984\n",
      "\n",
      "Epoch: 13\n",
      "  Training loss:          0.000\n",
      "  Training accuracy:      1.000\n",
      "  Validation loss:        0.070\n",
      "  Validation accuracy:    0.984\n",
      "\n",
      "Epoch: 14\n",
      "  Training loss:          0.000\n",
      "  Training accuracy:      1.000\n",
      "  Validation loss:        0.069\n",
      "  Validation accuracy:    0.985\n",
      "\n",
      "CPU times: user 1h 52min 44s, sys: 1h 38min 56s, total: 3h 31min 41s\n",
      "Wall time: 1h 10min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.run(stopping_rule=\"epoch\",epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0842ebe0-e67c-466c-9913-5474ccd053e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 3\n",
    "update_args = {\"q\": 5,\n",
    "               \"niter\": 2\n",
    "              }\n",
    "def svd_tensor_hook(grad):\n",
    "    if len(grad.size()) == 2:\n",
    "        U, S, V = torch.svd_lowrank(grad, **update_args)\n",
    "        U, S, V = U[:,:rank], S[:rank], V[:,:rank]\n",
    "        return (U * S) @ V.T\n",
    "    else:\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a1c96d9-ef6e-4668-833e-c337b6e33cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.236210 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.188549 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.128634 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.131950 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.092262 \n",
      "\n",
      "Epoch 6\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.091042 \n",
      "\n",
      "Epoch 7\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.092272 \n",
      "\n",
      "Epoch 8\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.082221 \n",
      "\n",
      "Epoch 9\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.078572 \n",
      "\n",
      "Epoch 10\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.084984 \n",
      "\n",
      "Epoch 11\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.112008 \n",
      "\n",
      "Epoch 12\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.088917 \n",
      "\n",
      "Epoch 13\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.102968 \n",
      "\n",
      "Epoch 14\n",
      "-----------------------\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.082971 \n",
      "\n",
      "Done!\n",
      "CPU times: user 2h 42min 47s, sys: 0 ns, total: 2h 42min 47s\n",
      "Wall time: 59min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for p in model.parameters():\n",
    "    p.register_hook(svd_tensor_hook)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e688d23-200a-4208-bc76-dfc175e8f018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
